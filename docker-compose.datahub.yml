# docker-compose.datahub.yml
version: '3.8'

################################################################################
#                          RÉSEAU COMMUN DATAHUB                               #
################################################################################
networks:
  datahub_network:
    name: datahub_network

################################################################################
#                                SERVICES DATAHUB                               #
################################################################################
services:

  ################################################################################
  # 1) Zookeeper (prérequis Kafka)                                             #
  ################################################################################
  zookeeper:
    image: confluentinc/cp-zookeeper:${DATAHUB_CONFLUENT_VERSION}
    hostname: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD-SHELL", "echo srvr | nc zookeeper 2181"]
      interval: 5s
      timeout: 5s
      retries: 3
      start_period: 30s
    networks:
      - datahub_network

  ################################################################################
  # 2) Kafka Broker                                                             #
  ################################################################################
  broker:
    image: ${DATAHUB_CONFLUENT_KAFKA_IMAGE}:${DATAHUB_CONFLUENT_VERSION}
    hostname: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:${DATAHUB_MAPPED_KAFKA_BROKER_PORT}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_HEAP_OPTS: "-Xms256m -Xmx256m"
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"
      KAFKA_MESSAGE_MAX_BYTES: 5242880
      KAFKA_MAX_MESSAGE_BYTES: 5242880
    healthcheck:
      test: ["CMD-SHELL", "nc -z broker 9092"]
      interval: 1s
      timeout: 5s
      retries: 5
      start_period: 60s
    ports:
      - "${DATAHUB_MAPPED_KAFKA_BROKER_PORT}:9092"
    volumes:
      - broker:/var/lib/kafka/data
    networks:
      - datahub_network

  ################################################################################
  # 3) Schema Registry (Confluent)                                              #
  ################################################################################
  schema-registry:
    image: confluentinc/cp-schema-registry:${DATAHUB_CONFLUENT_VERSION}
    hostname: schema-registry
    depends_on:
      broker:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schemaregistry
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
    healthcheck:
      test: ["CMD-SHELL", "nc -z schema-registry 8081"]
      interval: 1s
      timeout: 5s
      retries: 3
      start_period: 60s
    ports:
      - "8082:8081"
    networks:
      - datahub_network

  ################################################################################
  # 4) Elasticsearch                                                            #
  ################################################################################
  elasticsearch:
    image: ${DATAHUB_SEARCH_IMAGE}:${DATAHUB_SEARCH_TAG}
    hostname: elasticsearch
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xms256m -Xmx512m -Dlog4j2.formatMsgNoLookups=true"
    healthcheck:
      test: ["CMD-SHELL", "curl -sS --fail http://elasticsearch:9200/_cluster/health?wait_for_status=yellow&timeout=0s"]
      interval: 1s
      timeout: 5s
      retries: 3
      start_period: 20s
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - datahub_network

  ################################################################################
  # 5) MySQL (Metadata DB pour DataHub)                                         #
  ################################################################################
  mysql:
    image: mysql:${DATAHUB_MYSQL_VERSION}
    hostname: mysql
    command:
      - --character-set-server=utf8mb4
      - --collation-server=utf8mb4_bin
      - --default-authentication-plugin=mysql_native_password
    environment:
      MYSQL_DATABASE: datahub
      MYSQL_USER: datahub
      MYSQL_PASSWORD: datahub
      MYSQL_ROOT_PASSWORD: datahub
      MYSQL_ROOT_HOST: '%'
    healthcheck:
      test: ["CMD-SHELL", "mysqladmin ping -h mysql -u$$MYSQL_USER --password=$$MYSQL_PASSWORD"]
      interval: 1s
      timeout: 5s
      retries: 5
      start_period: 20s
    ports:
      - "3306:3306"
    volumes:
      - mysqldata:/var/lib/mysql
    networks:
      - datahub_network

  ################################################################################
  # 6) Elasticsearch‐Setup (pour créer les index initialement)                   #
  ################################################################################
  elasticsearch-setup:
    image: ${DATAHUB_ELASTIC_SETUP_IMAGE:-acryldata/datahub-elasticsearch-setup}:${DATAHUB_VERSION}
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_USE_SSL: "false"
      USE_AWS_ELASTICSEARCH: "false"
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
    labels:
      datahub_setup_job: "true"
    networks:
      - datahub_network

  ################################################################################
  # 7) Kafka‐Setup (pour créer topics & schémas)                                 #
  ################################################################################
  kafka-setup:
    image: ${DATAHUB_KAFKA_SETUP_IMAGE:-acryldata/datahub-kafka-setup}:${DATAHUB_VERSION}
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    environment:
      DATAHUB_PRECREATE_TOPICS: "false"
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      USE_CONFLUENT_SCHEMA_REGISTRY: "TRUE"
    labels:
      datahub_setup_job: "true"
    networks:
      - datahub_network

  ################################################################################
  # 8) MySQL‐Setup (création de la base & des tables “datahub” initiales)        #
  ################################################################################
  mysql-setup:
    image: ${DATAHUB_MYSQL_SETUP_IMAGE:-acryldata/datahub-mysql-setup}:${DATAHUB_VERSION}
    depends_on:
      mysql:
        condition: service_healthy
    environment:
      MYSQL_HOST: mysql
      MYSQL_PORT: 3306
      MYSQL_USERNAME: datahub
      MYSQL_PASSWORD: datahub
      DATAHUB_DB_NAME: datahub
    labels:
      datahub_setup_job: "true"
    networks:
      - datahub_network

  ################################################################################
  # 9) DataHub GMS (Graph Metadata Service)                                     #
  ################################################################################
  datahub-gms:
    image: ${DATAHUB_GMS_IMAGE}:${DATAHUB_VERSION}
    hostname: datahub-gms
    depends_on:
      datahub-upgrade:
        condition: service_completed_successfully
    environment:
      DATAHUB_SERVER_TYPE: quickstart
      DATAHUB_TELEMETRY_ENABLED: "true"
      DATAHUB_UPGRADE_HISTORY_KAFKA_CONSUMER_GROUP_ID: generic-duhe-consumer-job-client-gms

      EBEAN_DATASOURCE_DRIVER: com.mysql.jdbc.Driver
      EBEAN_DATASOURCE_HOST: mysql:3306
      EBEAN_DATASOURCE_USERNAME: datahub
      EBEAN_DATASOURCE_PASSWORD: datahub
      EBEAN_DATASOURCE_URL: >-
        jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8

      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX: "true"
      ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX: "true"

      ENTITY_REGISTRY_CONFIG_PATH: /datahub/datahub-gms/resources/entity-registry.yml
      ENTITY_SERVICE_ENABLE_RETENTION: "true"
      ES_BULK_REFRESH_POLICY: WAIT_UNTIL
      GRAPH_SERVICE_DIFF_MODE_ENABLED: "true"
      GRAPH_SERVICE_IMPL: elasticsearch

      JAVA_OPTS: "-Xms1g -Xmx1g"
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_CONSUMER_STOP_ON_DESERIALIZATION_ERROR: "true"
      KAFKA_SCHEMAREGISTRY_URL: http://schema-registry:8081

      MAE_CONSUMER_ENABLED: "true"
      MCE_CONSUMER_ENABLED: "true"
      METADATA_SERVICE_AUTH_ENABLED: "false"
      PE_CONSUMER_ENABLED: "true"
      UI_INGESTION_ENABLED: "true"
    healthcheck:
      test: ["CMD-SHELL", "curl -sS --fail http://datahub-gms:8080/health"]
      interval: 1s
      timeout: 5s
      retries: 3
      start_period: 90s
    ports:
      - "8580:8080"
    volumes:
      - ./plugins:/etc/datahub/plugins
    labels:
      datahub_service: "true"
    networks:
      - datahub_network

  ################################################################################
  # 10) DataHub‐Upgrade (pour initialiser / mettre à jour les métadonnées)       #
  ################################################################################
  datahub-upgrade:
    image: ${DATAHUB_UPGRADE_IMAGE}:${DATAHUB_VERSION}
    hostname: datahub-upgrade
    depends_on:
      elasticsearch-setup:
        condition: service_completed_successfully
      kafka-setup:
        condition: service_completed_successfully
      mysql-setup:
        condition: service_completed_successfully
    command:
      - "-u"
      - "SystemUpdate"
    environment:
      EBEAN_DATASOURCE_USERNAME: datahub
      EBEAN_DATASOURCE_PASSWORD: datahub
      EBEAN_DATASOURCE_HOST: mysql:3306
      EBEAN_DATASOURCE_URL: >-
        jdbc:mysql://mysql:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
      EBEAN_DATASOURCE_DRIVER: com.mysql.jdbc.Driver
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_SCHEMAREGISTRY_URL: http://schema-registry:8081
      ELASTICSEARCH_HOST: elasticsearch
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_INDEX_BUILDER_MAPPINGS_REINDEX: "true"
      ELASTICSEARCH_INDEX_BUILDER_SETTINGS_REINDEX: "true"
      ELASTICSEARCH_BUILD_INDICES_CLONE_INDICES: "false"
      GRAPH_SERVICE_IMPL: elasticsearch
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      ENTITY_REGISTRY_CONFIG_PATH: /datahub/datahub-gms/resources/entity-registry.yml
      BACKFILL_BROWSE_PATHS_V2: "true"
      REPROCESS_DEFAULT_BROWSE_PATHS_V2: "false"
    labels:
      datahub_setup_job: "true"
    networks:
      - datahub_network

  ################################################################################
  # 11) DataHub Frontend (React)                                                #
  ################################################################################
  datahub-frontend-react:
    image: ${DATAHUB_FRONTEND_IMAGE}:${DATAHUB_VERSION}
    hostname: datahub-frontend-react
    depends_on:
      datahub-gms:
        condition: service_healthy
    environment:
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_SECRET: YouKnowNothing
      DATAHUB_APP_VERSION: 1.0
      DATAHUB_PLAY_MEM_BUFFER_SIZE: 10MB
      JAVA_OPTS: >-
        -Xms512m -Xmx512m
        -Dhttp.port=9002
        -Dconfig.file=datahub-frontend/conf/application.conf
        -Djava.security.auth.login.config=datahub-frontend/conf/jaas.conf
        -Dlogback.configurationFile=datahub-frontend/conf/logback.xml
        -Dlogback.debug=false
        -Dpidfile.path=/dev/null
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      DATAHUB_TRACKING_TOPIC: DataHubUsageEvent_v1
      ELASTIC_CLIENT_HOST: elasticsearch
      ELASTIC_CLIENT_PORT: 9200
    ports:
      - "9002:9002"
    volumes:
      - ./plugins:/etc/datahub/plugins
    networks:
      - datahub_network

  ################################################################################
  # 12) DataHub Actions (pour ingestion asynchrone)                              #
  ################################################################################
  datahub-actions:
    image: ${DATAHUB_ACTIONS_IMAGE}:${DATAHUB_VERSION}
    hostname: actions
    depends_on:
      datahub-gms:
        condition: service_healthy
    environment:
      ACTIONS_CONFIG: ""
      ACTIONS_EXTRA_PACKAGES: ""
      DATAHUB_GMS_HOST: datahub-gms
      DATAHUB_GMS_PORT: 8080
      DATAHUB_GMS_PROTOCOL: http
      DATAHUB_SYSTEM_CLIENT_ID: __datahub_system
      DATAHUB_SYSTEM_CLIENT_SECRET: JohnSnowKnowsNothing
      KAFKA_BOOTSTRAP_SERVER: broker:29092
      KAFKA_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
      METADATA_AUDIT_EVENT_NAME: MetadataAuditEvent_v4
      METADATA_CHANGE_LOG_VERSIONED_TOPIC_NAME: MetadataChangeLog_Versioned_v1
      SCHEMA_REGISTRY_URL: http://schema-registry:8081
    networks:
      - datahub_network

################################################################################
#                                  VOLUMES                                      #
################################################################################
volumes:
  broker:
  esdata:
  mysqldata:
  zkdata:
  zklogs:
